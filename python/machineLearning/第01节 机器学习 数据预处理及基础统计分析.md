在机器学习之前，我们需要先了解一下数据预处理及基础统计分析方法。

# 一、数据探索

## 1.1、统计量分析

### 1.1.1）集中趋势的度量
从一组数字中我们可以学到什么？

在机器学习（和数学）中，通常存在三个我们感兴趣的值：
- 平均值-平均值
- 中位数-中点值
- 众数-最常见的值

示例：我们已经注册了13辆车的速度：
```text
speed = [99,86,87,88,111,86,103,87,94,78,77,85,86]
```

平均值，中间值或最常见的速度值是多少？

#### 均值/平均值 Mean
要计算平均值，请找到所有值的总和，然后将总和除以值的数量：
```text
(99+86+87+88+111+86+103+87+94+78+77+85+86) / 13 = 89.77
```

NumPy模块为此提供了一种方法。在我们的NumPy教程中了解有关NumPy模块的信息。

例如：

使用NumPy中的mean()方法查找平均速度：
```text
import numpy

speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]
x = numpy.mean(speed)
print(x)
```
output:
```text
89.76923076923077
```

#### 中值/中位数 Median
中值是对所有值进行排序后的中间值：
```text
77, 78, 85, 86, 86, 86, 87, 87, 88, 94, 99, 103, 111
```

在找到中位数之前，对数字进行排序很重要。

NumPy模块为此提供了一种方法：

例如：

使用NumPy中的median()方法查找中间值：
```text
import numpy

speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]
x = numpy.median(speed)
print(x)
```
output:
```text
87.0
```

如果中间有两个数字，则将这些数字之和除以2。
```text
77, 78, 85, 86, 86, 86, 87, 87, 94, 98, 99, 103

(86 + 87) / 2 = 86.5
```

例如：

使用NumPy模块：
```text
import numpy

speed = [99, 86, 87, 88, 86, 103, 87, 94, 78, 77, 85, 86]
x = numpy.median(speed)
print(x)
```
output:
```text
86.5
```

#### 众数 Mode
众数值是出现次数最多的值：
```text
99,86, 87, 88, 111,86, 103, 87, 94, 78, 77, 85,86 = 86
```

SciPy模块为此提供了一种方法。在我们的SciPy教程中了解有关SciPy模块的信息。

例如：

使用SciPy中的mode()方法查找出现次数最多的数字：
```text
from scipy import stats

speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]
x = stats.mode(speed, keepdims=True)
print(x)
```
output:
```text
ModeResult(mode=array([86]), count=array([3]))
```

平均值，中位数和众数是机器学习中经常使用的技术，因此了解它们背后的概念很重要。

### 1.1.2）离散趋势的度量

#### 极差(Range)
极差(Range)：全组内数据最大值与最小值的差。
```text
import numpy

speed = [86, 87, 88, 86, 87, 85, 86]
x = numpy.max(speed) - numpy.min(speed)
print(x)
```
output:
```text
3
```

极差易受极端值影响，且不能反映数据的中间分布情况。

#### 标准差(Standard Deviation)/方差(Variance)
**1）什么是标准偏差?**

标准偏差是一个数字，描述值的分散程度。

低标准偏差意味着大多数数字接近均值（平均值）。

高标准偏差表示这些值分布在更宽的范围内。

示例：这次我们已经注册了7辆车的速度：
```text
speed = [86, 87, 88, 86, 87, 85, 86]
```

标准偏差为：0.9。

意味着大多数值在平均值的0.9范围内，即86.4 - 0.9 ~ 86.4 + 0.9之间。

让我们对范围更广的数字进行选择：
```text
speed = [32, 111, 138, 28, 59, 77, 97]
```

标准偏差为：37.85。

这意味着大多数值在平均值的37.85范围内，即77.4。

如您所见，较高的标准偏差表示这些值分布在较宽的范围内。

NumPy模块有一种计算标准偏差的方法：

例如：

使用NumPy中的std()方法查找标准偏差：
```text
import numpy

speed = [86, 87, 88, 86, 87, 85, 86]
x = numpy.std(speed)
print(x)
```
output:
```text
0.9035079029052513
```

例如：
```text
import numpy

speed = [32, 111, 138, 28, 59, 77, 97]
x = numpy.std(speed)
print(x)
```
output:
```text
37.84501153334721
```

**2）方差(Variance)**

方差是另一个数字，指示值的分散程度。

实际上，如果采用方差的平方根，则会得到标准偏差！

或反之，如果将标准偏差乘以自身，就可以得到方差！

要计算方差，必须执行以下操作：

2.1）找到均值：
```text
(32+111+138+28+59+77+97) / 7 = 77.4
```

2.2）对于每个值：找到与平均值的差：
```text
32 - 77.4 = -45.4
111 - 77.4 =  33.6
138 - 77.4 =  60.6
28 - 77.4 = -49.4
59 - 77.4 = -18.4
77 - 77.4 = - 0.4
97 - 77.4 =  19.6
```

2.3）对于每个差异：找到平方值：
```text
(-45.4)2 = 2061.16
(33.6)2 = 1128.96
(60.6)2 = 3672.36
(-49.4)2 = 2440.36
(-18.4)2 =  338.56
(- 0.4)2 =    0.16
(19.6)2 =  384.16
```

2.4）方差是这些平方差的平均值：
```text
(2061.16+1128.96+3672.36+2440.36+338.56+0.16+384.16) / 7 = 1432.2
```

幸运的是，NumPy有一种计算方差的方法：

例如：

使用NumPy中的var()方法来查找差异：
```text
import numpy

speed = [32, 111, 138, 28, 59, 77, 97]
x = numpy.var(speed)
print(x)
```
output:
```text
1432.2448979591834
```

**3）标准偏差(Standard Deviation)**
例如：

使用NumPy中的std()方法查找标准偏差：
```text
import numpy

speed = [32, 111, 138, 28, 59, 77, 97]
x = numpy.std(speed)
print(x)
```
output:
```text
37.84501153334721
```

```text
import numpy as np

arr = np.array([1, 2, 3, 4])
print("variance of [1,2,3,4]:", np.var(arr))
print("sqrt of variance [1,2,3,4]:", np.sqrt(np.var(arr)))
print("standard deviation: np.std()", np.std(arr))
```
output:
```text
variance of [1,2,3,4]: 1.25
sqrt of variance [1,2,3,4]: 1.118033988749895
standard deviation: np.std() 1.118033988749895
```

**4）符号**

标准偏差通常用符号Sigma：σ

方差通常用符号Sigma Square: σ2

标准偏差和方差是机器学习中经常使用的术语，因此了解如何获取它们以及它们背后的概念非常重要。

#### 百分位数

在统计数据中使用百分位数可为您提供一个数字，该数字描述了给定百分比值低于的值。

示例：假设我们有一个街道上所有人口的年龄数组。
```text
ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]
```

什么是75.百分位数？答案是43，这意味着75％的人是43岁或以下。

NumPy模块具有一种用于找到指定百分位数的方法：

例如：

使用NumPy中的percentile()方法查找百分位数：
```text
import numpy

ages = [5, 31, 43, 48, 50, 41, 7, 11, 15, 39, 80, 82, 32, 2, 8, 6, 25, 36, 27, 61, 31]
x = numpy.percentile(ages, 75)
print(x)
```
output:
```text
43.0
```

例如：

90％的人口年龄是多少岁？
```text
import numpy

ages = [5, 31, 43, 48, 50, 41, 7, 11, 15, 39, 80, 82, 32, 2, 8, 6, 25, 36, 27, 61, 31]
x = numpy.percentile(ages, 90)
print(x)
```
output:
```text
61.0
```

```text
import numpy as np

a = np.array([[10, 7, 4], [3, 2, 1]])
print('我们的数组是：')
print(a)

print('调用 percentile() 函数：')
# 50% 的分位数，就是 a 里排序之后的中位数
print(np.percentile(a, 50))

# axis 为 0，在纵列上求
print(np.percentile(a, 50, axis=0))

# axis 为 1，在横行上求
print(np.percentile(a, 50, axis=1))

# 保持维度不变
print(np.percentile(a, 50, axis=1, keepdims=True))
```
output:
```text
我们的数组是：
[[10  7  4] [ 3  2  1]]
调用 percentile() 函数：
3.5
[6.5 4.5 2.5]
[7. 2.]
[[7.] [2.]]
```

#### 变异系数

极差，方差，标准差都是有计量单位的。

如果要比较不同数据的离散程度，需要用变异系数。

变异系数是一组数据中的极差、四分位差或标准差等离散指标与算术平均数的比率。

```text
import numpy as np
import scipy.stats as st

# 学生体重测试数据
weights = np.array([75.0, 64.0, 47.4, 66.9, 62.2, 62.2, 58.7, 63.5,
                    66.6, 64.0, 57.0, 69.0, 56.9, 50.0, 72.0])

# 极差
R_weights = np.max(weights) - np.min(weights)
print('体重数据的极差：%0.2f' % R_weights)
R_weights1 = np.ptp(weights)
print('体重数据的极差：%0.2f' % R_weights1)

# 均值的两种方式
w_mean = np.mean(weights)
w_mean1 = weights.mean()
# 限定范围的数据求均值，排除离群值（只统计60~70之间的数据），注意不要想当然的排除。
limitedMean = st.tmean(weights, (60, 70))

# 对数据进行排列
sorted_weight = sorted(weights, reverse=True)

# 求中位数（在对称分布比如正态分布和T分布，均值和中位数很接近；在偏态分布的情况下，比如F分布，均值和中位数相差较大）
median_weight = np.median(weights)
# 求分位数
quantiles = np.quantile(weights, [0.1, 0.2, 0.4, 0.6, 0.8, 1])
print('学生体重的[10%, 20%, 40%, 60%, 80%, 100%]分位数：', quantiles)

# 方差和方差的无偏估计
# 总体方差，即方差的有偏估计，这里的样本误差其实指的是母体误差，也就是说除以的是n而非（n-1）
v = np.var(weights)
# 样本方差，即方差的无偏估计，也就是真正意义上的样本误差，除以的是(n-1)
v_unb = st.tvar(weights)
print('体重数据方差的估计为：%0.2f,无偏估计为：%0.2f' % (v, v_unb))

# 标准差，同样存在有偏和无偏估计
s = np.std(weights)  # 有偏的标准差，同上
s_unb = st.tstd(weights)  # 无偏的标准差，同上
print('体重数据标准差的估计为：%0.2f,无偏估计为：%0.2f' % (s, s_unb))

# 变异系数(标准差的无偏估计除以均值再乘100)，无量纲，百分数表示
cv = s_unb / w_mean * 100
print('体重数据的变异系数为：', np.round(cv, 2), '%')
```
output:
```text
体重数据的极差：27.60
体重数据的极差：27.60
学生体重的[10%, 20%, 40%, 60%, 80%, 100%]分位数： [52.76 56.98 62.2  64.   67.32 75.  ]
体重数据方差的估计为：52.71,无偏估计为：56.47
体重数据标准差的估计为：7.26,无偏估计为：7.51
体重数据的变异系数为： 12.05 %
```

### 1.1.3）描述性统计函数
python Dataframe.describe()方法
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.describe()
print(pt1)
```
output:（describe方法会忽略掉非数字字段）
```text
             Age      Salary
count   5.000000     5.00000
mean   35.000000  7000.00000
std     7.905694  1581.13883
min    25.000000  5000.00000
25%    30.000000  6000.00000
50%    35.000000  7000.00000
75%    40.000000  8000.00000
max    45.000000  9000.00000
```

## 1.2、数据透视表
数据透视表是一种分类汇总数据的方法。

在 Python 中，我们可以使用 Pandas 库中的pivot_table 函数来创建和操作数据透视表，
相比Excel，Python可以更多更快的处理数据。

首先，介绍一下pivot_table 函数：
```text
pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')
```
看一下参数主要的作用：
```text
data:DataFrame

values:被计算的数据项，设定需要被聚合操作的列（需要显示的列）

index:每个pivot_table必须拥有一个index,必选参数，设定数据的行索引，可以设置多层索引，多次索引时按照需求确定索引顺序。

columns:必选参数，设定列索引，用来显示字符型数据，和fill_value搭配使用。

aggfunc:聚合函数， pivot_table后新dataframe的值都会通过aggfunc进行运算。默认numpy.mean求平均。

fill_values:填充NA值（设定缺失值）。默认不填充，可以指定。

margins：添加行列的总计，默认FALSE不显示。TRUE显示。

dropna：如果整行都为NA值，则进行丢弃，默认TRUE丢弃。FALSE时，被保留。

margins_name：margins = True 时，设定margins 行/列的名称。‘all’ 默认值
```

1）按照不同类进行计数统计

为了结算每个城市不同性别的平均收入，我们可以利用pivot_table函数进行统计：
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary', aggfunc='mean')
print(pt1)
```
output:
```text
Gender    Female    Male
City                    
Beijing   7000.0  7000.0
Shanghai     NaN  7000.0
```
2）如果要知道每个城市不同性别的总收入，只需要设定aggfunc函数为sum进行求和：
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary', aggfunc='sum')
print(pt1)
```
output:
```text
Gender     Female     Male
City                      
Beijing   14000.0   7000.0
Shanghai      NaN  14000.0
```

3）可以看到这两个数据透视表是有缺失值的，pivot_table有一个参数fill_value，就是用来填充这些缺失值的。
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary', fill_value=0, aggfunc='sum')
print(pt1)
```
output:
```text
Gender     Female     Male
City                      
Beijing   14000.0   7000.0
Shanghai      0     14000.0
```
4）pivot_table方法还支持对透视表进行统计计算，而且会新建一个列来存放计算结果。

这个统计需要用到以下两个参数：
- margins，设定是否添加汇总列，一般设置为True。
- margins_name，汇总列的名称。

```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary',
                     fill_value=0, aggfunc='sum', margins=True, margins_name="汇总")
print(pt1)
```
output:
```text
Gender    Female   Male     汇总
City                          
Beijing    14000   7000  21000
Shanghai       0  14000  14000
汇总         14000  21000  35000
```

5）筛选数据透视表中的数据

（1）仅保留汇总列的数据。
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary',
                     fill_value=0, aggfunc='sum', margins=True, margins_name="汇总")
print(pt1["汇总"])
```
output:
```text
City
Beijing     21000
Shanghai    14000
汇总          35000
Name: 汇总, dtype: int64
```

（2）获取男性和女性的汇总数据。
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary',
                     fill_value=0, aggfunc='sum', margins=True, margins_name="汇总")
print(pt1[["Female", "Male"]])
```
output:
```text
Gender    Female   Male
City                   
Beijing    14000   7000
Shanghai       0  14000
汇总         14000  21000
```

6）使用字段列表对数据透视表中的数据进行排序
```text
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],
        'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],
        'Age': [25, 30, 35, 40, 45],
        'City': ['Beijing', 'Shanghai', 'Beijing', 'Shanghai', 'Beijing'],
        'Salary': [5000, 6000, 7000, 8000, 9000]}
df = pd.DataFrame(data)
pt1 = df.pivot_table(index='City', columns='Gender', values='Salary',
                     fill_value=0, aggfunc='sum', margins=True, margins_name="汇总")
print("=================== 排序前 ====================")
print(pt1)
print("=============== 按照 汇总 排序后 ================")
print(pt1.sort_values(by="汇总"))
```
output:
```text
=================== 排序前 ====================
Gender    Female   Male     汇总
City                          
Beijing    14000   7000  21000
Shanghai       0  14000  14000
汇总         14000  21000  35000
=============== 按照 汇总 排序后 ================
Gender    Female   Male     汇总
City                          
Shanghai       0  14000  14000
Beijing    14000   7000  21000
汇总         14000  21000  35000
```

以上就是用Python构造数据透视表的内容介绍。
数据透视表是数据分析中非常重要的工具，掌握它可以让你更加高效地进行数据处理和可视化呈现。

## 1.3、相关性分析

1）散点图，散点图矩阵

2）相关系数，python Dataframe.corr方法
```text
import pandas as pd

df = pd.read_csv("data.csv")
print("==========数据信息：==========")
print(df.info())
print("==========数据相关性分析：==========")
print(df.corr())
```
output:
```text
==========数据信息：==========
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 169 entries, 0 to 168
Data columns (total 4 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Duration  169 non-null    int64  
 1   Pulse     169 non-null    int64  
 2   Maxpulse  169 non-null    int64  
 3   Calories  164 non-null    float64
dtypes: float64(1), int64(3)
memory usage: 5.4 KB
None
==========数据相关性分析：==========
          Duration     Pulse  Maxpulse  Calories
Duration  1.000000 -0.155408  0.009403  0.922717
Pulse    -0.155408  1.000000  0.786535  0.025121
Maxpulse  0.009403  0.786535  1.000000  0.203813
Calories  0.922717  0.025121  0.203813  1.000000
```
根据结果可以看出，Calories字段与Duration字段相关性大，达到0.922717。

# 二、数据预处理

## 2.1、数据清洗

### 2.1.1）缺失值处理

删除

插补

不处理

### 2.1.2）异常值处理

删除

缺失处理

平均值修正

不处理

## 2.2、数据标准化

标准分数

log变换

## 2.3、属性规约

对属性值进行之约束设置。

# 三、利用python做基础统计分析

见python Pandas内容

## 3.1、数据获取（可用数据集）：
1、Kaggle&天池（大数据竞赛平台）；

2、UCI数据集网站（包含多领域数据）；

3、scikit-learn网址（适合学习阶段）

## 3.2、python常用的工具包：（即用即查）
数据分析工具：numpy ；scipy ；pandas

数据可视化工具：matplotlib

数据挖掘与建模工具：scikit-learn；TensorFlow

官方主页：NumPy 官方主页：SciPy 官方主页：Matplotlib — Visualization with Python

官方主页：scikit-learn: machine learning in Python — scikit-learn 0.16.1 documentation官方主页：pandas - Python Data Analysis Library

## 3.3、简单数据分类：
1、定类数据；

2、定序数据；

3、定距数据（间隔）：可以界定数据大小同时，可测定差值，但无绝对零点，乘除无意义。例如温度。

4、定比数据（比率）：可以界定数据大小，可测定差值，有绝对零点，乘除有意义，最常见的数值型数据。

## 3.4、基本的描述性分析
### 3.4.1）数据预览
```text
df=pd.read_csv("D:/Users/DXX/Desktop/dxx.code/Python学习/HR_comma_sep.csv")
df.info()
df.describe()
df.sample(n=10)  # 抽样个数
df.sample(frac=0.0005)  # 抽样百分比
```
info()——用于获取 DataFrame 的简要摘要，以便快速浏览数据集。

describe()——用于对数据进行统计学估计，
输出行名分别为：count(行数)，mean(平均值)，std(标准差)，
min(最小值），25%(第一四分位数)，50%(第二四分位数)，75%(第三四分位数)，max(最大值)。

### 3.4.2）异常值分析——需要对数据进行单变量及整体异常值分析（具体问题具体分析）
```text
### 对每组变量进行异常值分析
# "satisfaction_level"
sl_s=df["satisfaction_level"]
sl_s.describe()
sl_s[sl_s.isnull()]
df[sl_s.isnull()]
sl_s=sl_s.dropna()   #dropna（）删除nan；fillna（）填充nan
np.histogram(sl_s.values,bins=np.arange(0.0,1.1,0.1))   #负偏

# "last_evaluation"
le_s=df["last_evaluation"]
le_s.describe()
le_s[le_s<=1]
q_low=le_s.quantile(q=0.25)
q_high=le_s.quantile(q=0.75)
q_interval=q_high-q_low
k=1.5
le_s=le_s[le_s>q_low-k*q_interval][le_s<q_high+k*q_interval]   #上下四分位数阈值范围外
le_s
np.histogram(le_s.values,bins=np.arange(0.0,1.1,0.1))   #负偏

# "number_project"
np_s=df["number_project"]
np_s.describe()
np_s.value_counts(normalize=True).sort_index()   #normalize=True——返回比例；sort_index()——按照序号排序

# "average_montly_hours"&"time_spend_company"
amh_s=df["average_montly_hours"]
amh_s.describe()
amh_s=amh_s[amh_s>amh_s.quantile(q=0.25)-1.5*(amh_s.quantile(q=0.75)-amh_s.quantile(q=0.25))][amh_s<amh_s.quantile(q=0.75)+1.5*(amh_s.quantile(q=0.75)-amh_s.quantile(q=0.25))]
np.histogram(amh_s.values,bins=10)
np.histogram(amh_s.values,bins=np.arange(amh_s.min(),amh_s.max()+10,10))   #范围——左闭右开
amh_s.value_counts(bins=np.arange(amh_s.min(),amh_s.max()+10,10))   #区间——左开右闭

# "Work_accident"&"left"&"promotion_last_5years"
wa_s=df["Work_accident"]
wa_s.describe()
wa_s.value_counts()
left_s=df["left"]
left_s.describe()
left_s.value_counts()
pl5_s=df["promotion_last_5years"]
pl5_s.describe()
pl5_s.value_counts()

# "salary" &"department"
df.salary.unique()   #查看salary的类别，包括哪些工作类型
s_s=df["salary"]
s_s.value_counts()
print(s_s.where(s_s!="nme"))
s_s.where(s_s!="nme").dropna()
df.department.unique()  #查看sales的类别，包括哪些工作类型
d_s=df["department"]
d_s.value_counts(normalize=True).sort_values()

### 整体去除数据异常值
df=df.dropna(axis=0,how="any")  #axis=0—行；how=“any”有一个空值删除；“all”全为空删除
df=df[df["last_evaluation"]<=1][df["salary"]!="nme"]
```
最后实现：将数据中的nan值、超出正常范围的取值和不正确的属性值去除。

### 3.4.3）对比分析
```text
print(df.iloc[:,[1,8]])
df.loc[:,["last_evaluation","department"]]   
# loc和iloc的区别：loc按照表格名称索引；iloc按照位置索引；
```
loc和iloc的区别：loc按照表格名称索引；iloc按照位置索引。

```text
# 分组，并计算均值
df.loc[:,["last_evaluation","department"]].groupby("department").mean()

# 分组，应用匿名函数lambda进行组内运算
df.loc[:,["average_montly_hours","department"]].groupby("department")["average_montly_hours"].apply(lambda x:x.max()-x.min())   #自定义计算极差

```
groupby()——主要的作用是进行数据的分组以及分组后地组内运算（简单的均值计算 or 指自定义匿名函数运算）。

### 3.4.4）分布分析
```text
import scipy.stats as ss
import pandas as pd
import numpy as np
ss.norm  #生成一个正态分布的对象
ss.norm.stats(moments="mvsk")  #正态分布的均值；方差；偏度；峰度；
ss.norm.pdf(0.0)  #x=0对应的概率密度函数值
ss.norm.ppf(0.9)  #取值范围在[0,1]——累积分布函数为0.9对应的x值
ss.norm.cdf(2)    #x为2时，累积分布函数的取值.（范围[0,1]）
ss.norm.cdf(2)-ss.norm.cdf(-2)  
ss.norm.rvs(size=10)  #生成10个正态分布的数据
#（其他用法同正态分布）
ss.chi2   #卡方分布
ss.t    #t分布
ss.f   #f分布  
```

## 3.5、数据简单可视化分析：matplotlib；seaborn；plotly
1、柱状图
```text
### 柱状图
# arange()生成一个指定1终点2起点和3步长的列表
plt.bar(np.arange(len(df["salary"].value_counts())),df["salary"].value_counts())  
plt.show()
```

2、直方图
```text
### 直方图
sns.displot(df["satisfaction_level"],bins=10,kde=True) #kde=True有曲线
plt.show()
```

3、箱线图
```text
###箱线图
sns.boxplot(y=df["time_spend_company"])
sns.boxplot(x=df["time_spend_company"],saturation=0.75,whis=3)  # whis上界
```

4、折线图
```text
### 折线图
sns.pointplot(x="time_spend_company",y="left",data=df)
```

5、饼图
```text
### 饼图
lbs=df["department"].value_counts().index
explodes=[0.1 if i=="sales" else 0 for i in lbs]  # 与其他类别分隔开
plt.pie(df["department"].value_counts(normalize=True),explode=explodes,labels=lbs,autopct="%1.1f%%",colors=sns.color_palette("Greens"))
```
